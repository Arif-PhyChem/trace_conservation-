{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](\n",
        "https://colab.research.google.com/github/Arif-PhyChem/trace_conservation/blob/main/physics_agnostic.ipynb)"
      ],
      "metadata": {
        "id": "qesUG7jE9wh8"
      },
      "id": "qesUG7jE9wh8"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "ca5cecd1",
      "metadata": {
        "id": "ca5cecd1",
        "outputId": "26a20733-7226-4d75-d99e-3a5e7c038a35",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'MLQD'...\n",
            "remote: Enumerating objects: 1008, done.\u001b[K\n",
            "remote: Counting objects: 100% (284/284), done.\u001b[K\n",
            "remote: Compressing objects: 100% (190/190), done.\u001b[K\n",
            "remote: Total 1008 (delta 135), reused 199 (delta 93), pack-reused 724\u001b[K\n",
            "Receiving objects: 100% (1008/1008), 34.97 MiB | 24.85 MiB/s, done.\n",
            "Resolving deltas: 100% (427/427), done.\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "import os\n",
        "\n",
        "! git clone https://github.com/Arif-PhyChem/MLQD.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "e1e1a3dc",
      "metadata": {
        "id": "e1e1a3dc",
        "outputId": "3d8e0e05-f465-4e80-d6cc-289b6f81173f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.25.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.64.1)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2024.6.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n",
            "Collecting sklearn\n",
            "  Downloading sklearn-0.0.post12.tar.gz (2.6 kB)\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
            "\n",
            "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
            "\u001b[31m╰─>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
            "\u001b[1;36mhint\u001b[0m: See above for details.\n",
            "Requirement already satisfied: hyperopt in /usr/local/lib/python3.10/dist-packages (0.2.7)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from hyperopt) (1.25.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from hyperopt) (1.11.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from hyperopt) (1.16.0)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from hyperopt) (3.3)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from hyperopt) (0.18.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from hyperopt) (4.66.4)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from hyperopt) (2.2.1)\n",
            "Requirement already satisfied: py4j in /usr/local/lib/python3.10/dist-packages (from hyperopt) (0.10.9.7)\n"
          ]
        }
      ],
      "source": [
        "# install the required packages\n",
        "\n",
        "! pip install tensorflow\n",
        "! pip install sklearn\n",
        "! pip install hyperopt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "8e9b292c",
      "metadata": {
        "id": "8e9b292c"
      },
      "outputs": [],
      "source": [
        "\n",
        "mlqd_dir='MLQD/dev_ver'\n",
        "sys.path.append(mlqd_dir)\n",
        "\n",
        "from evolution import quant_dyn\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get data\n",
        "! git clone https://github.com/Arif-PhyChem/trace_conservation.git"
      ],
      "metadata": {
        "id": "jA7P5vCdaRIr",
        "outputId": "da9aac12-7420-4c7c-c550-45d25526c2bb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "jA7P5vCdaRIr",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'trace_conservation'...\n",
            "remote: Enumerating objects: 115, done.\u001b[K\n",
            "remote: Counting objects: 100% (36/36), done.\u001b[K\n",
            "remote: Compressing objects: 100% (23/23), done.\u001b[K\n",
            "remote: Total 115 (delta 3), reused 36 (delta 3), pack-reused 79\u001b[K\n",
            "Receiving objects: 100% (115/115), 324.69 MiB | 33.66 MiB/s, done.\n",
            "Resolving deltas: 100% (4/4), done.\n",
            "Updating files: 100% (54/54), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! ls trace_conservation/training_data/"
      ],
      "metadata": {
        "id": "QvYABW1-ak5P",
        "outputId": "70678b5c-4f7b-44e4-b4a4-d8f387e4b549",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "QvYABW1-ak5P",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "state_1  state_2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "742a43b6",
      "metadata": {
        "id": "742a43b6",
        "outputId": "a20ce272-3119-476f-f0f7-f4999d80f3b6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=================================================================\n",
            "MLQD is a python package developed for Machine Learning-based Quantum Dissipative Dynamics,\n",
            " \t\t\t\t  Version 1.1.1\n",
            "\t\t\t https://github.com/Arif-PhyChem/MLQD\n",
            "\n",
            " \t\t\t Copyright (c) 2023 Arif Ullah\n",
            "\n",
            "All rights reserved. This work is licensed under the Apache Software License 2.0\n",
            "\n",
            "\n",
            "The above copyright notice and this permission notice shall be included \n",
            "in all copies or substantial portions of the Software.\n",
            "\n",
            "\n",
            "The software is provided \"as is\" without warranty of any kind, express or implied, \n",
            "including but not limited to the warranties ofmerchantability, fitness for a particular \n",
            "purpose and noninfringement. In no event shall the authors or copyright holders be \n",
            "liable for any claim, damages or other liability, whether in an action of contract, tort or otherwise, \n",
            "arising from, out of or in connection with the software or the use or other dealings in the software.\n",
            "\n",
            "\n",
            "\t\t\t\t Cite as:\n",
            "\n",
            "1) Ullah A. and Dral P. O., Computer Physics Communications, 2023, 294, 108940\n",
            "2) Ullah A. and Dral P. O., New Journal of Physics, 2021, 23(11), 113019\n",
            "3) Ullah A. and Dral P. O., Nature Communications, 2022, 13(1), 1930\n",
            "4) Ullah A. and Dral P. O., Journal of Physical Chemistry Letters, 2022, 13(26), 6037\n",
            "5) Rodriguez L. E. H.; Ullah A.; Espinosa K. J. R.; Dral P. O. and Kananenka A. A., Machine Learning: Science and Technology, 2022, 3(4), 045016\n",
            "6) Ullah, A., Rodriguez, L. E. H., Dral P. O., and Kananenka, A. A., Frontiers in Physics, 2023, 11, 1223973\n",
            "\n",
            "Contributers List:\n",
            "\n",
            "1) Arif Ullah (main) \n",
            "2) Pavlo O. Dral\n",
            "=================================================================\n",
            "MLQD is started at 2024-06-14 11:06:54.902692\n",
            "=================================================================\n",
            "Setting \"systemType\" to SB\n",
            "MLQD is running with the option QDmodel =  createQDmodel\n",
            "Setting ML Model Type \"QDmodelType\" to RCDYN\n",
            "Setting number of states \"n_states\" to 2\n",
            "You have chosen not to prepare the input files, othewise you should pass \"True\" to prepInput\n",
            "Model will be saved as RC_SB_model_1\n",
            "Xfilein is trace_conservation/training_data/sb/physics_agnostic/state_1/x\n",
            "YfileIn is trace_conservation/training_data/sb/physics_agnostic/state_1/y\n",
            "You have chosen not to optimize the hyper parameters of the model, otherwise you should pass \"True\" to hyperParam\n",
            "=================================================================\n",
            "Setting patience for early stopping to 30\n",
            "Setting number of epochs for training to 500\n",
            "Setting length of each row in input file \"xlength\" to 41\n",
            "Setting propagation time \"time\" to 10\n",
            "Setting time_step to 0.05\n",
            "Running with default option: pinn=False, training an unconstrained neural network (PINN)\n",
            "Running with default prior option 0 with no trace conservation\n",
            "MLQD is grabbing column # 1 as was passed through \"dataCol\"\n",
            "=================================================================\n",
            "=================================================================\n",
            "Train.ml_RCDYN: Looking for best_param.pkl\n",
            "=================================================================\n",
            "Train.ml_RCDYN: best_param.pkl not found, thus training CNN model with the default structure\n",
            "=================================================================\n",
            "Data: Checking to see whether the input data files trace_conservation/training_data/sb/physics_agnostic/state_1/x.npy and trace_conservation/training_data/sb/physics_agnostic/state_1/y.npy exist\n",
            "Data: Loading data files trace_conservation/training_data/sb/physics_agnostic/state_1/x.npy and trace_conservation/training_data/sb/physics_agnostic/state_1/y.npy\n",
            "Data: splitting data into sub-training/validation sets with 80/20 % ratio\n",
            "=================================================================\n",
            "cnn.OSTL_default: Running wth EarlyStopping of patience = 30\n",
            "cnn.OSTL_default: Running with batch size = 16 and epochs = 500\n",
            "=================================================================\n",
            "Epoch 1/500\n",
            "2000/2000 - 20s - loss: 0.0012 - val_loss: 2.0163e-05 - 20s/epoch - 10ms/step\n",
            "Epoch 2/500\n",
            "2000/2000 - 19s - loss: 3.2247e-05 - val_loss: 3.2909e-06 - 19s/epoch - 9ms/step\n",
            "Epoch 3/500\n",
            "2000/2000 - 17s - loss: 3.2032e-05 - val_loss: 3.7673e-05 - 17s/epoch - 9ms/step\n",
            "Epoch 4/500\n",
            "2000/2000 - 17s - loss: 2.7670e-05 - val_loss: 1.6196e-05 - 17s/epoch - 9ms/step\n",
            "Epoch 5/500\n",
            "2000/2000 - 18s - loss: 2.1436e-05 - val_loss: 1.0183e-05 - 18s/epoch - 9ms/step\n",
            "Epoch 6/500\n",
            "2000/2000 - 18s - loss: 1.5685e-05 - val_loss: 4.3994e-06 - 18s/epoch - 9ms/step\n",
            "Epoch 7/500\n",
            "2000/2000 - 17s - loss: 1.3219e-05 - val_loss: 1.1810e-05 - 17s/epoch - 9ms/step\n",
            "Epoch 8/500\n",
            "2000/2000 - 18s - loss: 9.4677e-06 - val_loss: 3.3209e-05 - 18s/epoch - 9ms/step\n",
            "Epoch 9/500\n",
            "2000/2000 - 21s - loss: 9.3991e-06 - val_loss: 6.6712e-06 - 21s/epoch - 11ms/step\n",
            "Epoch 10/500\n",
            "2000/2000 - 18s - loss: 5.3492e-06 - val_loss: 7.8669e-06 - 18s/epoch - 9ms/step\n",
            "Epoch 11/500\n",
            "2000/2000 - 19s - loss: 4.9056e-06 - val_loss: 4.6959e-05 - 19s/epoch - 9ms/step\n",
            "Epoch 12/500\n",
            "2000/2000 - 20s - loss: 3.3474e-06 - val_loss: 3.3719e-06 - 20s/epoch - 10ms/step\n",
            "Epoch 13/500\n",
            "2000/2000 - 18s - loss: 3.6010e-06 - val_loss: 8.2802e-07 - 18s/epoch - 9ms/step\n",
            "Epoch 14/500\n",
            "2000/2000 - 19s - loss: 3.6850e-06 - val_loss: 3.5320e-06 - 19s/epoch - 9ms/step\n",
            "Epoch 15/500\n",
            "2000/2000 - 19s - loss: 3.0689e-06 - val_loss: 2.6601e-06 - 19s/epoch - 9ms/step\n",
            "Epoch 16/500\n",
            "2000/2000 - 17s - loss: 2.5522e-06 - val_loss: 6.1704e-07 - 17s/epoch - 9ms/step\n",
            "Epoch 17/500\n",
            "2000/2000 - 19s - loss: 3.5025e-06 - val_loss: 3.7363e-06 - 19s/epoch - 9ms/step\n",
            "Epoch 18/500\n",
            "2000/2000 - 17s - loss: 2.6387e-06 - val_loss: 1.1295e-06 - 17s/epoch - 9ms/step\n",
            "Epoch 19/500\n",
            "2000/2000 - 17s - loss: 2.5269e-06 - val_loss: 6.3841e-07 - 17s/epoch - 9ms/step\n",
            "Epoch 20/500\n",
            "2000/2000 - 19s - loss: 2.8620e-06 - val_loss: 5.4433e-07 - 19s/epoch - 10ms/step\n",
            "Epoch 21/500\n",
            "2000/2000 - 20s - loss: 2.1937e-06 - val_loss: 1.3804e-06 - 20s/epoch - 10ms/step\n",
            "Epoch 22/500\n",
            "2000/2000 - 19s - loss: 2.0634e-06 - val_loss: 2.8548e-06 - 19s/epoch - 9ms/step\n",
            "Epoch 23/500\n",
            "2000/2000 - 19s - loss: 2.3623e-06 - val_loss: 3.2599e-06 - 19s/epoch - 9ms/step\n",
            "Epoch 24/500\n",
            "2000/2000 - 17s - loss: 1.8919e-06 - val_loss: 8.0043e-07 - 17s/epoch - 9ms/step\n",
            "Epoch 25/500\n",
            "2000/2000 - 18s - loss: 2.4174e-06 - val_loss: 6.3754e-07 - 18s/epoch - 9ms/step\n",
            "Epoch 26/500\n",
            "2000/2000 - 18s - loss: 1.8895e-06 - val_loss: 2.5952e-07 - 18s/epoch - 9ms/step\n",
            "Epoch 27/500\n",
            "2000/2000 - 18s - loss: 1.7987e-06 - val_loss: 4.2773e-06 - 18s/epoch - 9ms/step\n",
            "Epoch 28/500\n",
            "2000/2000 - 18s - loss: 2.0444e-06 - val_loss: 1.9824e-06 - 18s/epoch - 9ms/step\n",
            "Epoch 29/500\n",
            "2000/2000 - 19s - loss: 2.1937e-06 - val_loss: 1.5362e-07 - 19s/epoch - 9ms/step\n",
            "Epoch 30/500\n",
            "2000/2000 - 18s - loss: 2.5134e-06 - val_loss: 9.1106e-07 - 18s/epoch - 9ms/step\n",
            "Epoch 31/500\n",
            "2000/2000 - 17s - loss: 1.5027e-06 - val_loss: 2.7737e-07 - 17s/epoch - 9ms/step\n",
            "Epoch 32/500\n",
            "2000/2000 - 17s - loss: 1.7975e-06 - val_loss: 3.0994e-06 - 17s/epoch - 9ms/step\n",
            "Epoch 33/500\n",
            "2000/2000 - 20s - loss: 1.8290e-06 - val_loss: 1.5196e-06 - 20s/epoch - 10ms/step\n",
            "Epoch 34/500\n",
            "2000/2000 - 21s - loss: 1.8625e-06 - val_loss: 4.3292e-07 - 21s/epoch - 10ms/step\n",
            "Epoch 35/500\n",
            "2000/2000 - 21s - loss: 1.5078e-06 - val_loss: 3.0016e-07 - 21s/epoch - 10ms/step\n",
            "Epoch 36/500\n",
            "2000/2000 - 18s - loss: 1.9910e-06 - val_loss: 1.1532e-06 - 18s/epoch - 9ms/step\n",
            "Epoch 37/500\n",
            "2000/2000 - 17s - loss: 1.4553e-06 - val_loss: 4.6164e-06 - 17s/epoch - 9ms/step\n",
            "Epoch 38/500\n",
            "2000/2000 - 22s - loss: 1.5923e-06 - val_loss: 4.2733e-06 - 22s/epoch - 11ms/step\n",
            "Epoch 39/500\n",
            "2000/2000 - 19s - loss: 1.8598e-06 - val_loss: 1.2165e-06 - 19s/epoch - 10ms/step\n",
            "Epoch 40/500\n",
            "2000/2000 - 19s - loss: 1.7383e-06 - val_loss: 7.0961e-07 - 19s/epoch - 10ms/step\n",
            "Epoch 41/500\n",
            "2000/2000 - 18s - loss: 1.9725e-06 - val_loss: 4.0040e-07 - 18s/epoch - 9ms/step\n",
            "Epoch 42/500\n",
            "2000/2000 - 18s - loss: 2.3223e-06 - val_loss: 3.5246e-07 - 18s/epoch - 9ms/step\n",
            "Epoch 43/500\n",
            "2000/2000 - 20s - loss: 1.1619e-06 - val_loss: 5.7099e-07 - 20s/epoch - 10ms/step\n",
            "Epoch 44/500\n",
            "2000/2000 - 18s - loss: 1.5832e-06 - val_loss: 3.2558e-07 - 18s/epoch - 9ms/step\n",
            "Epoch 45/500\n",
            "2000/2000 - 18s - loss: 1.4708e-06 - val_loss: 4.5993e-06 - 18s/epoch - 9ms/step\n",
            "Epoch 46/500\n",
            "2000/2000 - 19s - loss: 1.4722e-06 - val_loss: 1.4113e-07 - 19s/epoch - 10ms/step\n",
            "Epoch 47/500\n",
            "2000/2000 - 21s - loss: 1.3807e-06 - val_loss: 2.0935e-07 - 21s/epoch - 11ms/step\n",
            "Epoch 48/500\n",
            "2000/2000 - 20s - loss: 1.5055e-06 - val_loss: 2.0958e-06 - 20s/epoch - 10ms/step\n",
            "Epoch 49/500\n",
            "2000/2000 - 19s - loss: 1.4635e-06 - val_loss: 1.1188e-06 - 19s/epoch - 9ms/step\n",
            "Epoch 50/500\n",
            "2000/2000 - 19s - loss: 1.2063e-06 - val_loss: 1.9108e-07 - 19s/epoch - 10ms/step\n",
            "Epoch 51/500\n"
          ]
        }
      ],
      "source": [
        "\n",
        "param={\n",
        "    'n_states': 2,\n",
        "      'QDmodel': 'createQDmodel',     # str: create QD model. The dafault option is useQDmodel\n",
        "      'QDmodelType': 'RCDYN',           # str: The type of model. Here KRR and the default option is OSTL\n",
        "      'prepInput' : 'False',           # str: Prepare input files from the data (Default 'False')\n",
        "      'XfileIn': 'trace_conservation/training_data/sb/physics_agnostic/state_1/x',           # str: (Optional) The prepared X file will be saved at the provided file name\n",
        "      'YfileIn': 'trace_conservation/training_data/sb/physics_agnostic/state_1/y',           # str: (Optional) The prepared Y file will be saved at the provided file name\n",
        "      'time': 10,\n",
        "      'time_step': 0.05,\n",
        "      'dataCol': 1,\n",
        "      'xlength': 41,\n",
        "      'hyperParam': 'False',           # str: Default is 'False', we can pass 'True' (optimize the hyperparameters) or 'False' (don't optimize and run with the default values)\n",
        "      'patience': 30,\n",
        "      'OptEpochs': 30,\n",
        "      'TrEpochs': 500,\n",
        "      'max_evals': 30,\n",
        "      'systemType': 'SB', # str: (Not optional) Need to define, wether your model is spin-boson (SB) or FMO complex (FMO)\n",
        "      'dataPath': '/home/dell/arif/pypackage/sb/data/training_data/sym',\n",
        "      'QDmodelOut': 'RC_SB_model_1'    # str: (Optional), providing a name to save the model at\n",
        "      }\n",
        "quant_dyn(**param)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c5e6a6b5-86f5-42f2-a1df-b7ad9422d466",
      "metadata": {
        "id": "c5e6a6b5-86f5-42f2-a1df-b7ad9422d466"
      },
      "outputs": [],
      "source": [
        "xx = np.load('/home/dell/arif/pypackage/sb/data/test_set/2_epsilon-0.0_Delta-1.0_lambda-0.2_gamma-10.0_beta-0.75.npy')\n",
        "\n",
        "\n",
        "n_states = 2\n",
        "xlength = 41\n",
        "time = 10\n",
        "time_step = 0.05\n",
        "time_range=0\n",
        "tt = time_range\n",
        "for i in range(0, xlength + int(time/time_step)-1):\n",
        "    tt += time_step\n",
        "    time_range = np.append(time_range, tt)\n",
        "\n",
        "\n",
        "\n",
        "model_1 = keras.models.load_model('state_1/RC_SB_model_0.keras') # state 1 CNN model\n",
        "model_2 = keras.models.load_model('state_2/RC_SB_model_0.keras') # state 2 CNN model\n",
        "\n",
        "models = [model_1, model_2]\n",
        "\n",
        "x = np.zeros((xlength, n_states), dtype=float)\n",
        "y = np.zeros((len(time_range), n_states), dtype=float)\n",
        "yhat = np.zeros((1, n_states), dtype=float)\n",
        "\n",
        "trace = np.zeros((len(time_range), 1), dtype=float)\n",
        "labels = [1, 4]\n",
        "\n",
        "i = 0\n",
        "for label in labels:\n",
        "    x[:,i] = np.real(xx[0:xlength, label])\n",
        "    i += 1\n",
        "y[0:xlength, :] = x[:,:]\n",
        "\n",
        "for i in range (0, xlength):\n",
        "  tr = 0\n",
        "  for j in labels:\n",
        "    tr += x[i, j]\n",
        "  trace[i, 0] = tr\n",
        "\n",
        "print('****************************************************************')\n",
        "print('Predicting dynamics')\n",
        "print('****************************************************************')\n",
        "\n",
        "for i in range(xlength, len(time_range)):\n",
        "    l =0\n",
        "    for j in range (0, n_states):\n",
        "        x_pred = x[:, j]\n",
        "        x_pred = x_pred.reshape(1, x.shape[0], 1) # reshape the input\n",
        "        yhat[0, j] =  models[l].predict(x_pred, verbose=0)[0][0]\n",
        "        l += 1\n",
        "\n",
        "    # correction\n",
        "    trace = np.sum(yhat)\n",
        "\n",
        "    x = np.delete(x, 0, 0)\n",
        "    x = np.r_[x, yhat]\n",
        "    y[i, :] = yhat[0, :]\n",
        "np.save('tc_traj', np.c_['-1', time_range[:], y[:]])\n",
        "print('Dynamics with no trace conservation is generated and saved in a file with name tc_traj.npy')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}