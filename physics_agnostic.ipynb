{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](\n",
        "https://colab.research.google.com/github/Arif-PhyChem/trace_conservation/blob/main/physics_agnostic.ipynb)"
      ],
      "metadata": {
        "id": "qesUG7jE9wh8"
      },
      "id": "qesUG7jE9wh8"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "ca5cecd1",
      "metadata": {
        "id": "ca5cecd1",
        "outputId": "a341efe9-c0ae-41dd-af4d-ef6ab5edae49",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'MLQD'...\n",
            "remote: Enumerating objects: 1008, done.\u001b[K\n",
            "remote: Counting objects: 100% (284/284), done.\u001b[K\n",
            "remote: Compressing objects: 100% (190/190), done.\u001b[K\n",
            "remote: Total 1008 (delta 135), reused 199 (delta 93), pack-reused 724\u001b[K\n",
            "Receiving objects: 100% (1008/1008), 34.97 MiB | 11.68 MiB/s, done.\n",
            "Resolving deltas: 100% (427/427), done.\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "import os\n",
        "\n",
        "! git clone https://github.com/Arif-PhyChem/MLQD.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "e1e1a3dc",
      "metadata": {
        "id": "e1e1a3dc",
        "outputId": "9ad4e3f5-d1a9-4ee9-c2e2-8b775b35110a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Collecting tensorflow\n",
            "  Downloading tensorflow-2.16.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (589.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m589.8/589.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Collecting h5py>=3.10.0 (from tensorflow)\n",
            "  Downloading h5py-3.11.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m64.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Collecting ml-dtypes~=0.3.1 (from tensorflow)\n",
            "  Downloading ml_dtypes-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m67.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.31.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.64.1)\n",
            "Collecting tensorboard<2.17,>=2.16 (from tensorflow)\n",
            "  Downloading tensorboard-2.16.2-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m63.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting keras>=3.0.0 (from tensorflow)\n",
            "  Downloading keras-3.3.3-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m61.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.25.2)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.0.0->tensorflow) (13.7.1)\n",
            "Collecting namex (from keras>=3.0.0->tensorflow)\n",
            "  Downloading namex-0.0.8-py3-none-any.whl (5.8 kB)\n",
            "Collecting optree (from keras>=3.0.0->tensorflow)\n",
            "  Downloading optree-0.11.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (311 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.2/311.2 kB\u001b[0m \u001b[31m32.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.6.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.17,>=2.16->tensorflow) (3.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.17,>=2.16->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.17,>=2.16->tensorflow) (3.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.0.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.0.0->tensorflow) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow) (0.1.2)\n",
            "Installing collected packages: namex, optree, ml-dtypes, h5py, tensorboard, keras, tensorflow\n",
            "  Attempting uninstall: ml-dtypes\n",
            "    Found existing installation: ml-dtypes 0.2.0\n",
            "    Uninstalling ml-dtypes-0.2.0:\n",
            "      Successfully uninstalled ml-dtypes-0.2.0\n",
            "  Attempting uninstall: h5py\n",
            "    Found existing installation: h5py 3.9.0\n",
            "    Uninstalling h5py-3.9.0:\n",
            "      Successfully uninstalled h5py-3.9.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.15.2\n",
            "    Uninstalling tensorboard-2.15.2:\n",
            "      Successfully uninstalled tensorboard-2.15.2\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.15.0\n",
            "    Uninstalling keras-2.15.0:\n",
            "      Successfully uninstalled keras-2.15.0\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.15.0\n",
            "    Uninstalling tensorflow-2.15.0:\n",
            "      Successfully uninstalled tensorflow-2.15.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tf-keras 2.15.1 requires tensorflow<2.16,>=2.15, but you have tensorflow 2.16.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed h5py-3.11.0 keras-3.3.3 ml-dtypes-0.3.2 namex-0.0.8 optree-0.11.0 tensorboard-2.16.2 tensorflow-2.16.1\n",
            "Collecting sklearn\n",
            "  Downloading sklearn-0.0.post12.tar.gz (2.6 kB)\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
            "\n",
            "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
            "\u001b[31m╰─>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
            "\u001b[1;36mhint\u001b[0m: See above for details.\n",
            "Requirement already satisfied: hyperopt in /usr/local/lib/python3.10/dist-packages (0.2.7)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from hyperopt) (1.25.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from hyperopt) (1.11.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from hyperopt) (1.16.0)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from hyperopt) (3.3)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from hyperopt) (0.18.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from hyperopt) (4.66.4)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from hyperopt) (2.2.1)\n",
            "Requirement already satisfied: py4j in /usr/local/lib/python3.10/dist-packages (from hyperopt) (0.10.9.7)\n"
          ]
        }
      ],
      "source": [
        "# install the required packages\n",
        "\n",
        "! pip install tensorflow --upgrade\n",
        "! pip install sklearn\n",
        "! pip install hyperopt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "8e9b292c",
      "metadata": {
        "id": "8e9b292c"
      },
      "outputs": [],
      "source": [
        "# Add MLQD's path to system path\n",
        "\n",
        "mlqd_dir='MLQD/dev_ver'\n",
        "sys.path.append(mlqd_dir)\n",
        "\n",
        "from evolution import quant_dyn\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get training and test data files from github\n",
        "! git clone https://github.com/Arif-PhyChem/trace_conservation.git"
      ],
      "metadata": {
        "id": "jA7P5vCdaRIr",
        "outputId": "699756ae-0b79-429b-870c-0d45282eafc6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "jA7P5vCdaRIr",
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'trace_conservation' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Physics agnostic model for spin boson (SB) model\n",
        "\n",
        "In the context of physics-agnostic neural networks, we train separate Convolutional Neural Networks (CNNs) for each element of the diagonal Reduced Density Matrix (RDM). To facilitate this process, we offer pre-prepared training files named 'x.npy' and 'y.npy'. However, if you wish to create your own training files, you can utilize the MLQD tool, available on GitHub at https://github.com/Arif-PhyChem/MLQD, in conjunction with the SB dataset from the QD3SET-1 database, which can be accessed via the DOI link https://doi.org/10.25452/figshare.plus.c.6389553"
      ],
      "metadata": {
        "id": "nbhZm6eHCZdx"
      },
      "id": "nbhZm6eHCZdx"
    },
    {
      "cell_type": "code",
      "source": [
        "# sb training files (x and y) for state 1 and state 2\n",
        "! ls trace_conservation/training_data/sb/physics_agnostic/state_1\n",
        "! ls trace_conservation/training_data/sb/physics_agnostic/state_2"
      ],
      "metadata": {
        "id": "QvYABW1-ak5P",
        "outputId": "e0f84f81-bc41-4f6c-991e-dad2d90dc843",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "QvYABW1-ak5P",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x.npy  y.npy\n",
            "x.npy  y.npy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below we train a CNN model for state 1 and state 2 independently. If you prefer not to train your own CNN model, you can opt to use the pre-trained models we have provided (scroll down below).\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "wOkECHf7Kqt5"
      },
      "id": "wOkECHf7Kqt5"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training CNN model for State-1 with MLQD\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "Gby5NTeAOayC"
      },
      "id": "Gby5NTeAOayC"
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "742a43b6",
      "metadata": {
        "id": "742a43b6",
        "outputId": "6e36b2c3-4155-4622-eb6b-4c873538203e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=================================================================\n",
            "MLQD is a python package developed for Machine Learning-based Quantum Dissipative Dynamics,\n",
            " \t\t\t\t  Version 1.1.1\n",
            "\t\t\t https://github.com/Arif-PhyChem/MLQD\n",
            "\n",
            " \t\t\t Copyright (c) 2023 Arif Ullah\n",
            "\n",
            "All rights reserved. This work is licensed under the Apache Software License 2.0\n",
            "\n",
            "\n",
            "The above copyright notice and this permission notice shall be included \n",
            "in all copies or substantial portions of the Software.\n",
            "\n",
            "\n",
            "The software is provided \"as is\" without warranty of any kind, express or implied, \n",
            "including but not limited to the warranties ofmerchantability, fitness for a particular \n",
            "purpose and noninfringement. In no event shall the authors or copyright holders be \n",
            "liable for any claim, damages or other liability, whether in an action of contract, tort or otherwise, \n",
            "arising from, out of or in connection with the software or the use or other dealings in the software.\n",
            "\n",
            "\n",
            "\t\t\t\t Cite as:\n",
            "\n",
            "1) Ullah A. and Dral P. O., Computer Physics Communications, 2023, 294, 108940\n",
            "2) Ullah A. and Dral P. O., New Journal of Physics, 2021, 23(11), 113019\n",
            "3) Ullah A. and Dral P. O., Nature Communications, 2022, 13(1), 1930\n",
            "4) Ullah A. and Dral P. O., Journal of Physical Chemistry Letters, 2022, 13(26), 6037\n",
            "5) Rodriguez L. E. H.; Ullah A.; Espinosa K. J. R.; Dral P. O. and Kananenka A. A., Machine Learning: Science and Technology, 2022, 3(4), 045016\n",
            "6) Ullah, A., Rodriguez, L. E. H., Dral P. O., and Kananenka, A. A., Frontiers in Physics, 2023, 11, 1223973\n",
            "\n",
            "Contributers List:\n",
            "\n",
            "1) Arif Ullah (main) \n",
            "2) Pavlo O. Dral\n",
            "=================================================================\n",
            "MLQD is started at 2024-06-17 04:01:54.747006\n",
            "=================================================================\n",
            "Setting \"systemType\" to SB\n",
            "MLQD is running with the option QDmodel =  createQDmodel\n",
            "Setting ML Model Type \"QDmodelType\" to RCDYN\n",
            "Setting number of states \"n_states\" to 2\n",
            "You have chosen not to prepare the input files, othewise you should pass \"True\" to prepInput\n",
            "Model will be saved as sb_model_4_state_1\n",
            "Xfilein is trace_conservation/training_data/sb/physics_agnostic/state_1/x\n",
            "YfileIn is trace_conservation/training_data/sb/physics_agnostic/state_1/y\n",
            "You have chosen not to optimize the hyper parameters of the model, otherwise you should pass \"True\" to hyperParam\n",
            "=================================================================\n",
            "Setting patience for early stopping to 30\n",
            "Setting number of epochs for training to 10\n",
            "Setting length of x-input \"xlength\" to default value 81\n",
            "Running with the the dafault propagation time: 20\n",
            "Running with the dafault time-step: 0.05\n",
            "Running with default option: pinn=False, training an unconstrained neural network (PINN)\n",
            "Running with default prior option 0 with no trace conservation\n",
            "Setting data column \"dataCol\" to None, full reduced density matrix will be considered\n",
            "=================================================================\n",
            "=================================================================\n",
            "Train.ml_RCDYN: Looking for best_param.pkl\n",
            "=================================================================\n",
            "Train.ml_RCDYN: best_param.pkl not found, thus training CNN model with the default structure\n",
            "=================================================================\n",
            "Data: Checking to see whether the input data files trace_conservation/training_data/sb/physics_agnostic/state_1/x.npy and trace_conservation/training_data/sb/physics_agnostic/state_1/y.npy exist\n",
            "Data: Loading data files trace_conservation/training_data/sb/physics_agnostic/state_1/x.npy and trace_conservation/training_data/sb/physics_agnostic/state_1/y.npy\n",
            "Data: splitting data into sub-training/validation sets with 80/20 % ratio\n",
            "=================================================================\n",
            "cnn.OSTL_default: Running wth EarlyStopping of patience = 30\n",
            "cnn.OSTL_default: Running with batch size = 16 and epochs = 10\n",
            "=================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "2000/2000 - 25s - 12ms/step - loss: 7.7301e-04 - val_loss: 1.5335e-05\n",
            "Epoch 2/10\n",
            "2000/2000 - 40s - 20ms/step - loss: 3.6076e-05 - val_loss: 7.1952e-06\n",
            "Epoch 3/10\n",
            "2000/2000 - 41s - 21ms/step - loss: 3.0469e-05 - val_loss: 2.3430e-05\n",
            "Epoch 4/10\n",
            "2000/2000 - 40s - 20ms/step - loss: 2.2564e-05 - val_loss: 3.8969e-06\n",
            "Epoch 5/10\n",
            "2000/2000 - 40s - 20ms/step - loss: 1.9450e-05 - val_loss: 3.7838e-06\n",
            "Epoch 6/10\n",
            "2000/2000 - 21s - 10ms/step - loss: 1.4409e-05 - val_loss: 4.0479e-06\n",
            "Epoch 7/10\n",
            "2000/2000 - 20s - 10ms/step - loss: 7.1651e-06 - val_loss: 1.2959e-06\n",
            "Epoch 8/10\n",
            "2000/2000 - 21s - 10ms/step - loss: 6.2882e-06 - val_loss: 2.0833e-06\n",
            "Epoch 9/10\n",
            "2000/2000 - 20s - 10ms/step - loss: 4.7819e-06 - val_loss: 2.6857e-06\n",
            "Epoch 10/10\n",
            "2000/2000 - 20s - 10ms/step - loss: 4.2141e-06 - val_loss: 4.1749e-06\n",
            "Restoring model weights from the end of the best epoch: 7.\n",
            "=================================================================\n",
            "cnn.OSTL_default: OSTL model is saved as \" sb_model_4_state_1.keras \"\n",
            "Train_ml.RCDYN: Time taken for training = 288.43226623535156 sec\n",
            "=================================================================\n",
            "=================================================================\n",
            "MLQD is ended at 2024-06-17 04:06:43.180998\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<evolution.quant_dyn at 0x7f70742baa70>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "# input for MLQD package, more details are given at https://github.com/Arif-PhyChem/MLQD\n",
        "param={\n",
        "    'n_states': 2,\n",
        "      'QDmodel': 'createQDmodel',     # str: create QD model. The dafault option is useQDmodel\n",
        "      'QDmodelType': 'RCDYN',           # str: The type of model. Here KRR and the default option is OSTL\n",
        "      'prepInput' : 'False',           # str: Prepare input files from the data (Default 'False')\n",
        "      'XfileIn': 'trace_conservation/training_data/sb/physics_agnostic/state_1/x',  # str: (Optional) The prepared X file\n",
        "      'YfileIn': 'trace_conservation/training_data/sb/physics_agnostic/state_1/y',  # str: (Optional) The prepared Y file\n",
        "      'hyperParam': 'False',  # str: Default is 'False', we can pass 'True' (optimize the hyperparameters) or 'False' (don't optimize and run with the default values)\n",
        "      'patience': 30,\n",
        "      'OptEpochs': 30,\n",
        "      'TrEpochs': 10,\n",
        "      'max_evals': 30,\n",
        "      'systemType': 'SB',\n",
        "      'QDmodelOut': 'sb_model_4_state_1'    # str: (Optional), providing a name to save the model at\n",
        "      }\n",
        "quant_dyn(**param)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training CNN model for State-2 with MLQD"
      ],
      "metadata": {
        "id": "TUhLiv5uOnfj"
      },
      "id": "TUhLiv5uOnfj"
    },
    {
      "cell_type": "code",
      "source": [
        "# input for MLQD package, more details are given at https://github.com/Arif-PhyChem/MLQD\n",
        "param={\n",
        "    'n_states': 2,\n",
        "      'QDmodel': 'createQDmodel',     # str: create QD model. The dafault option is useQDmodel\n",
        "      'QDmodelType': 'RCDYN',           # str: The type of model. Here KRR and the default option is OSTL\n",
        "      'prepInput' : 'False',           # str: Prepare input files from the data (Default 'False')\n",
        "      'XfileIn': 'trace_conservation/training_data/sb/physics_agnostic/state_2/x',           # str: (Optional) The prepared X file\n",
        "      'YfileIn': 'trace_conservation/training_data/sb/physics_agnostic/state_2/y',           # str: (Optional) The prepared Y file\n",
        "      'hyperParam': 'False',           # str: Default is 'False', we can pass 'True' (optimize the hyperparameters) or 'False' (don't optimize and run with the default values)\n",
        "      'patience': 30,\n",
        "      'OptEpochs': 30,\n",
        "      'TrEpochs': 10,\n",
        "      'max_evals': 30,\n",
        "      'systemType': 'SB',\n",
        "      'QDmodelOut': 'sb_model_4_state_2'    # str: (Optional), providing a name to save the model at\n",
        "      }\n",
        "quant_dyn(**param)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OUZFdj4AOmhW",
        "outputId": "8315c914-5fa3-4b15-b881-f3748008d906"
      },
      "id": "OUZFdj4AOmhW",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=================================================================\n",
            "MLQD is a python package developed for Machine Learning-based Quantum Dissipative Dynamics,\n",
            " \t\t\t\t  Version 1.1.1\n",
            "\t\t\t https://github.com/Arif-PhyChem/MLQD\n",
            "\n",
            " \t\t\t Copyright (c) 2023 Arif Ullah\n",
            "\n",
            "All rights reserved. This work is licensed under the Apache Software License 2.0\n",
            "\n",
            "\n",
            "The above copyright notice and this permission notice shall be included \n",
            "in all copies or substantial portions of the Software.\n",
            "\n",
            "\n",
            "The software is provided \"as is\" without warranty of any kind, express or implied, \n",
            "including but not limited to the warranties ofmerchantability, fitness for a particular \n",
            "purpose and noninfringement. In no event shall the authors or copyright holders be \n",
            "liable for any claim, damages or other liability, whether in an action of contract, tort or otherwise, \n",
            "arising from, out of or in connection with the software or the use or other dealings in the software.\n",
            "\n",
            "\n",
            "\t\t\t\t Cite as:\n",
            "\n",
            "1) Ullah A. and Dral P. O., Computer Physics Communications, 2023, 294, 108940\n",
            "2) Ullah A. and Dral P. O., New Journal of Physics, 2021, 23(11), 113019\n",
            "3) Ullah A. and Dral P. O., Nature Communications, 2022, 13(1), 1930\n",
            "4) Ullah A. and Dral P. O., Journal of Physical Chemistry Letters, 2022, 13(26), 6037\n",
            "5) Rodriguez L. E. H.; Ullah A.; Espinosa K. J. R.; Dral P. O. and Kananenka A. A., Machine Learning: Science and Technology, 2022, 3(4), 045016\n",
            "6) Ullah, A., Rodriguez, L. E. H., Dral P. O., and Kananenka, A. A., Frontiers in Physics, 2023, 11, 1223973\n",
            "\n",
            "Contributers List:\n",
            "\n",
            "1) Arif Ullah (main) \n",
            "2) Pavlo O. Dral\n",
            "=================================================================\n",
            "MLQD is started at 2024-06-17 04:07:14.788012\n",
            "=================================================================\n",
            "Setting \"systemType\" to SB\n",
            "MLQD is running with the option QDmodel =  createQDmodel\n",
            "Setting ML Model Type \"QDmodelType\" to RCDYN\n",
            "Setting number of states \"n_states\" to 2\n",
            "You have chosen not to prepare the input files, othewise you should pass \"True\" to prepInput\n",
            "Model will be saved as sb_model_4_state_2\n",
            "Xfilein is trace_conservation/training_data/sb/physics_agnostic/state_2/x\n",
            "YfileIn is trace_conservation/training_data/sb/physics_agnostic/state_2/y\n",
            "You have chosen not to optimize the hyper parameters of the model, otherwise you should pass \"True\" to hyperParam\n",
            "=================================================================\n",
            "Setting patience for early stopping to 30\n",
            "Setting number of epochs for training to 10\n",
            "Setting length of x-input \"xlength\" to default value 81\n",
            "Running with the the dafault propagation time: 20\n",
            "Running with the dafault time-step: 0.05\n",
            "Running with default option: pinn=False, training an unconstrained neural network (PINN)\n",
            "Running with default prior option 0 with no trace conservation\n",
            "Setting data column \"dataCol\" to None, full reduced density matrix will be considered\n",
            "=================================================================\n",
            "=================================================================\n",
            "Train.ml_RCDYN: Looking for best_param.pkl\n",
            "=================================================================\n",
            "Train.ml_RCDYN: best_param.pkl not found, thus training CNN model with the default structure\n",
            "=================================================================\n",
            "Data: Checking to see whether the input data files trace_conservation/training_data/sb/physics_agnostic/state_2/x.npy and trace_conservation/training_data/sb/physics_agnostic/state_2/y.npy exist\n",
            "Data: Loading data files trace_conservation/training_data/sb/physics_agnostic/state_2/x.npy and trace_conservation/training_data/sb/physics_agnostic/state_2/y.npy\n",
            "Data: splitting data into sub-training/validation sets with 80/20 % ratio\n",
            "=================================================================\n",
            "cnn.OSTL_default: Running wth EarlyStopping of patience = 30\n",
            "cnn.OSTL_default: Running with batch size = 16 and epochs = 10\n",
            "=================================================================\n",
            "Epoch 1/10\n",
            "2000/2000 - 25s - 13ms/step - loss: 7.7632e-04 - val_loss: 2.4601e-05\n",
            "Epoch 2/10\n",
            "2000/2000 - 39s - 19ms/step - loss: 3.8694e-05 - val_loss: 1.2234e-04\n",
            "Epoch 3/10\n",
            "2000/2000 - 20s - 10ms/step - loss: 2.9514e-05 - val_loss: 6.0353e-05\n",
            "Epoch 4/10\n",
            "2000/2000 - 22s - 11ms/step - loss: 2.9640e-05 - val_loss: 1.1396e-05\n",
            "Epoch 5/10\n",
            "2000/2000 - 19s - 10ms/step - loss: 1.2872e-05 - val_loss: 1.2418e-05\n",
            "Epoch 6/10\n",
            "2000/2000 - 21s - 11ms/step - loss: 1.1034e-05 - val_loss: 7.8681e-07\n",
            "Epoch 7/10\n",
            "2000/2000 - 42s - 21ms/step - loss: 6.4263e-06 - val_loss: 6.9284e-07\n",
            "Epoch 8/10\n",
            "2000/2000 - 20s - 10ms/step - loss: 5.2399e-06 - val_loss: 1.6140e-06\n",
            "Epoch 9/10\n",
            "2000/2000 - 21s - 11ms/step - loss: 4.6184e-06 - val_loss: 7.7520e-07\n",
            "Epoch 10/10\n",
            "2000/2000 - 41s - 20ms/step - loss: 3.4375e-06 - val_loss: 1.0720e-06\n",
            "Restoring model weights from the end of the best epoch: 7.\n",
            "=================================================================\n",
            "cnn.OSTL_default: OSTL model is saved as \" sb_model_4_state_2.keras \"\n",
            "Train_ml.RCDYN: Time taken for training = 290.29212737083435 sec\n",
            "=================================================================\n",
            "=================================================================\n",
            "MLQD is ended at 2024-06-17 04:12:05.083076\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<evolution.quant_dyn at 0x7f70742b8f40>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dynamics prediction for a test trajectory.\n",
        "For this task, we are leveraging the pre-trained CNN models that we have made available. However, if you have trained your own CNN models as previously described, you have the option to employ those models instead. This flexibility allows you to choose between our provided models and your custom-trained ones, depending on your specific requirements or preferences.  "
      ],
      "metadata": {
        "id": "_1LQlzmnLKQE"
      },
      "id": "_1LQlzmnLKQE"
    },
    {
      "cell_type": "code",
      "source": [
        "# Trained CNN models we provide\n",
        "! ls trace_conservation/trained_models/sb/physics_agnostic/state_1/\n",
        "! ls trace_conservation/trained_models/sb/physics_agnostic/state_2/\n",
        "# test tarjectory\n",
        "! ls trace_conservation/test_data/sb/\n",
        "! ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C_sVIUjdQemH",
        "outputId": "78e5b00a-cba9-4e5b-cc7a-c3fff0cfc9e3"
      },
      "id": "C_sVIUjdQemH",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RC_SB_model.keras\n",
            "RC_SB_model.keras\n",
            "2_epsilon-0.0_Delta-1.0_lambda-0.2_gamma-10.0_beta-0.75.npy\n",
            "MLQD  sample_data  sb_model_4_state_1.keras  sb_model_4_state_2.keras  trace_conservation\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "c5e6a6b5-86f5-42f2-a1df-b7ad9422d466",
      "metadata": {
        "id": "c5e6a6b5-86f5-42f2-a1df-b7ad9422d466",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87ddf69c-cd15-45e2-e711-b885aa00e1a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1.         0.        ]\n",
            " [0.99751179 0.00248821]\n",
            " [0.99012173 0.00987827]\n",
            " [0.97798798 0.02201202]\n",
            " [0.96131528 0.03868472]\n",
            " [0.94034549 0.05965451]\n",
            " [0.91535324 0.08464676]\n",
            " [0.88664318 0.11335682]\n",
            " [0.85453201 0.14546799]\n",
            " [0.8194022  0.1805978 ]\n",
            " [0.78162156 0.21837844]\n",
            " [0.74159207 0.25840793]\n",
            " [0.69973481 0.30026519]\n",
            " [0.65646874 0.34353126]\n",
            " [0.61223473 0.38776527]\n",
            " [0.56745937 0.43254063]\n",
            " [0.52258638 0.47741362]\n",
            " [0.47804442 0.52195558]\n",
            " [0.43425755 0.56574245]\n",
            " [0.39163615 0.60836385]\n",
            " [0.35057777 0.64942223]\n",
            " [0.31145206 0.68854794]\n",
            " [0.27461258 0.72538742]\n",
            " [0.24039247 0.75960753]\n",
            " [0.20907181 0.79092819]\n",
            " [0.18091836 0.81908164]\n",
            " [0.15617548 0.84382452]\n",
            " [0.13501437 0.86498563]\n",
            " [0.11763596 0.88236404]\n",
            " [0.1041336  0.8958664 ]\n",
            " [0.09458467 0.90541533]\n",
            " [0.08904005 0.91095995]\n",
            " [0.08750443 0.91249557]\n",
            " [0.08993894 0.91006106]\n",
            " [0.09626696 0.90373304]\n",
            " [0.10638424 0.89361576]\n",
            " [0.12015282 0.87984718]\n",
            " [0.1373963  0.8626037 ]\n",
            " [0.15790712 0.84209288]\n",
            " [0.18144891 0.81855109]\n",
            " [0.2077591  0.7922409 ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]]\n",
            "[[1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]]\n",
            "****************************************************************\n",
            "Predicting dynamics\n",
            "****************************************************************\n",
            "1.0069068223237991\n",
            "1.0103431642055511\n",
            "1.0145159363746643\n",
            "1.0183112621307373\n",
            "1.0210035145282745\n",
            "1.024695247411728\n",
            "1.0289469361305237\n",
            "1.0321916341781616\n",
            "1.035648226737976\n",
            "1.0386466979980469\n",
            "1.041901558637619\n",
            "1.0443188846111298\n",
            "1.0478107333183289\n",
            "1.0504144430160522\n",
            "1.0516981780529022\n",
            "1.052718460559845\n",
            "1.053493082523346\n",
            "1.0530050992965698\n",
            "1.0529894083738327\n",
            "1.0526035577058792\n",
            "1.0526756942272186\n",
            "1.0524164587259293\n",
            "1.0512917339801788\n",
            "1.0494094491004944\n",
            "1.046868547797203\n",
            "1.043584182858467\n",
            "1.0397471636533737\n",
            "1.0360052287578583\n",
            "1.0319167077541351\n",
            "1.028272956609726\n",
            "1.023906260728836\n",
            "1.0195233523845673\n",
            "1.0150503516197205\n",
            "1.009564220905304\n",
            "1.0041638612747192\n",
            "0.9984944462776184\n",
            "0.9932585060596466\n",
            "0.9883655905723572\n",
            "0.983601301908493\n",
            "0.9796051383018494\n",
            "0.9759610295295715\n",
            "0.9728756546974182\n",
            "0.9696318805217743\n",
            "0.9670900702476501\n",
            "0.9652590453624725\n",
            "0.9646649658679962\n",
            "0.965101808309555\n",
            "0.9664824604988098\n",
            "0.9684692919254303\n",
            "0.9713817983865738\n",
            "0.9742408245801926\n",
            "0.9780454784631729\n",
            "0.9823753088712692\n",
            "0.9877320826053619\n",
            "0.993733748793602\n",
            "0.999524399638176\n",
            "1.0053374469280243\n",
            "1.01189424097538\n",
            "1.0194351971149445\n",
            "1.0265407264232635\n",
            "1.0341053009033203\n",
            "1.0412446558475494\n",
            "1.049339383840561\n",
            "1.056879073381424\n",
            "1.0641314387321472\n",
            "1.0706387162208557\n",
            "1.0767457485198975\n",
            "1.0812592804431915\n",
            "1.0850129425525665\n",
            "1.0883300304412842\n",
            "1.090358555316925\n",
            "1.091233491897583\n",
            "1.0906265377998352\n",
            "1.0893099904060364\n",
            "1.0865618586540222\n",
            "1.0833119750022888\n",
            "1.078984558582306\n",
            "1.0743005275726318\n",
            "1.0687051117420197\n",
            "1.0629484057426453\n",
            "1.0561836957931519\n",
            "1.0486807525157928\n",
            "1.0407390594482422\n",
            "1.032297283411026\n",
            "1.0234952569007874\n",
            "1.0143767297267914\n",
            "1.0053093433380127\n",
            "0.9964383840560913\n",
            "0.9877247512340546\n",
            "0.9790206849575043\n",
            "0.9701635837554932\n",
            "0.9614440202713013\n",
            "0.952644556760788\n",
            "0.9439056515693665\n",
            "0.9356710612773895\n",
            "0.9278497099876404\n",
            "0.9210754632949829\n",
            "0.9150269627571106\n",
            "0.9098116755485535\n",
            "0.905332088470459\n",
            "0.9015380144119263\n",
            "0.8986295163631439\n",
            "0.8964940011501312\n",
            "0.8950020968914032\n",
            "0.8941484093666077\n",
            "0.8945035934448242\n",
            "0.8962748944759369\n",
            "0.8994466364383698\n",
            "0.9037559628486633\n",
            "0.9093299210071564\n",
            "0.9162737727165222\n",
            "0.9239021837711334\n",
            "0.9326408207416534\n",
            "0.9421250224113464\n",
            "0.9524409472942352\n",
            "0.9630473554134369\n",
            "0.9742092490196228\n",
            "0.9857537150382996\n",
            "0.9973352551460266\n",
            "1.0087361931800842\n",
            "1.0198748111724854\n",
            "1.0303972661495209\n",
            "1.0402839183807373\n",
            "1.0496087670326233\n",
            "1.058479368686676\n",
            "1.066846638917923\n",
            "1.0743776559829712\n",
            "1.0812748670578003\n",
            "1.0873095989227295\n",
            "1.092461347579956\n",
            "1.0963846445083618\n",
            "1.0992963910102844\n",
            "1.1009387373924255\n",
            "1.1015304327011108\n",
            "1.100812554359436\n",
            "1.0990188717842102\n",
            "1.0962174534797668\n",
            "1.0923956632614136\n",
            "1.0876725316047668\n",
            "1.082217276096344\n",
            "1.0760063529014587\n",
            "1.0691926181316376\n",
            "1.061818242073059\n",
            "1.0540404319763184\n",
            "1.0458541512489319\n",
            "1.0373845994472504\n",
            "1.0287383496761322\n",
            "1.0199744403362274\n",
            "1.0111944079399109\n",
            "1.0024590194225311\n",
            "0.9939500689506531\n",
            "0.9857166707515717\n",
            "0.9778049290180206\n",
            "0.9703076779842377\n",
            "0.9632320404052734\n",
            "0.9566327333450317\n",
            "0.9505549073219299\n",
            "0.9450221657752991\n",
            "0.9400548934936523\n",
            "0.9356725513935089\n",
            "0.9318787455558777\n",
            "0.9286970496177673\n",
            "0.926115870475769\n",
            "0.9240570962429047\n",
            "0.9225319027900696\n",
            "0.9216231405735016\n",
            "0.92128124833107\n",
            "0.9215222895145416\n",
            "0.9222943782806396\n",
            "0.9235906004905701\n",
            "0.9253628551959991\n",
            "0.927570253610611\n",
            "0.930172473192215\n",
            "0.9331246018409729\n",
            "0.9363758862018585\n",
            "0.93987837433815\n",
            "0.9435827434062958\n",
            "0.947431892156601\n",
            "0.9514389336109161\n",
            "0.9555192589759827\n",
            "0.9596571028232574\n",
            "0.9637928903102875\n",
            "0.9678893387317657\n",
            "0.9719123542308807\n",
            "0.9758630096912384\n",
            "0.9796739816665649\n",
            "0.9833227097988129\n",
            "0.9867739677429199\n",
            "0.9899324476718903\n",
            "0.9928545951843262\n",
            "0.9954884350299835\n",
            "0.9978206157684326\n",
            "0.9998378157615662\n",
            "1.0015310049057007\n",
            "1.0028943419456482\n",
            "1.0039316713809967\n",
            "1.0046358704566956\n",
            "1.005021721124649\n",
            "1.0051049888134003\n",
            "1.0048962533473969\n",
            "Dynamics with no trace conservation is generated and saved in a file with name tc_traj.npy\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "xx = np.load('trace_conservation/test_data/sb/2_epsilon-0.0_Delta-1.0_lambda-0.2_gamma-10.0_beta-0.75.npy')\n",
        "\n",
        "\n",
        "n_states = 2\n",
        "xlength = 41\n",
        "time = 10\n",
        "time_step = 0.05\n",
        "time_range=0\n",
        "tt = time_range\n",
        "\n",
        "# time range\n",
        "for i in range(0, xlength + int(time/time_step)-1):\n",
        "    tt += time_step\n",
        "    time_range = np.append(time_range, tt)\n",
        "\n",
        "\n",
        "# trained CNN models\n",
        "model_1 = tf.keras.models.load_model('sb_model_4_state_1.keras', compile=False) #('trace_conservation/trained_models/sb/physics_agnostic/state_1/RC_SB_model.keras') # state 1 CNN model\n",
        "model_2 = tf.keras.models.load_model('sb_model_4_state_2.keras', compile=False) #('trace_conservation/trained_models/sb/physics_agnostic/state_2/RC_SB_model.keras') # state 2 CNN model\n",
        "\n",
        "models = [model_1, model_2]\n",
        "\n",
        "x = np.zeros((xlength, n_states), dtype=float)\n",
        "y = np.zeros((len(time_range), n_states), dtype=float)\n",
        "yhat = np.zeros((1, n_states), dtype=float)\n",
        "\n",
        "trace = np.zeros((len(time_range), 1), dtype=float)\n",
        "labels = [1, 4]\n",
        "\n",
        "# short time dynamics for input\n",
        "i = 0\n",
        "for label in labels:\n",
        "    x[:,i] = np.real(xx[0:xlength, label])\n",
        "    i += 1\n",
        "y[0:xlength, :] = x[:,:]\n",
        "\n",
        "print(y)\n",
        "\n",
        "# trace of the input dynamics\n",
        "for i in range (0, xlength):\n",
        "  tr = 0\n",
        "  for j in labels:\n",
        "    tr += np.real(xx[i, j])\n",
        "  trace[i, 0] = tr\n",
        "\n",
        "print(trace)\n",
        "\n",
        "print('****************************************************************')\n",
        "print('Predicting dynamics')\n",
        "print('****************************************************************')\n",
        "\n",
        "for i in range(xlength, len(time_range)):\n",
        "    l =0\n",
        "    for j in range (0, n_states):\n",
        "        x_pred = x[:, j]\n",
        "        x_pred = x_pred.reshape(1, x.shape[0], 1) # reshape the input\n",
        "        yhat[0, j] =  models[l].predict(x_pred, verbose=0)[0][0]\n",
        "        l += 1\n",
        "\n",
        "    #\n",
        "    trace[i, 0] = np.sum(yhat)\n",
        "    print(trace[i,0])\n",
        "    x = np.delete(x, 0, 0)\n",
        "    x = np.r_[x, yhat]\n",
        "    y[i, :] = yhat[0, :]\n",
        "np.save('tc_traj', np.c_['-1', time_range[:], y[:]])\n",
        "print('Dynamics with no trace conservation is generated and saved in a file with name tc_traj.npy')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}